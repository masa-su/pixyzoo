{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynaNet\n",
    "- Original paper: [DynaNet: Neural Kalman Dynamical Model for Motion Estimation and Prediction](https://arxiv.org/abs/1908.03918)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## install modules and env setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f841d32a610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder(equation (3) in the paper): $\\mathbf{a}_{t}, \\boldsymbol{\\sigma}_{t}=f_{\\mathrm{encoder}}\\left(\\mathbf{x}_{t}\\right)$  \n",
    "\n",
    "Deterministic Transition(equation (5) in the paper): $\\mathbf{A}_{t}=\\mathrm{LSTM}\\left(\\mathbf{z}_{t-1}, \\mathbf{h}_{t-1}\\right)$\n",
    "\n",
    "Resampled Transition(equation (6), (7) in the paper):  \n",
    "$\\boldsymbol{\\alpha}=\\operatorname{LSTM}\\left(\\mathbf{z}_{t-1}, \\mathbf{h}_{t-1}\\right)$  \n",
    "$\\mathbf{A}_{t} \\sim \\operatorname{Dirichlet}(\\boldsymbol{\\alpha})$\n",
    "\n",
    "Kalman predictor(equation (8) in the paper):  \n",
    "$\\begin{aligned} \\mathbf{z}_{t | t-1} &=\\mathbf{A}_{t} \\mathbf{z}_{t-1 | t-1} \\\\ \\mathbf{P}_{t | t-1} &=\\mathbf{A}_{t} \\mathbf{P}_{t-1 | t-1} \\mathbf{A}_{t}^{T}+\\mathbf{Q}_{t} \\end{aligned}$  \n",
    "\n",
    "Kalman updator(equation (9) in the paper):  \n",
    "$\\begin{aligned} \\mathbf{r}_{t} &=\\mathbf{a}_{t}-\\mathbf{H}_{t} \\mathbf{z}_{t | t-1} \\\\ \\mathbf{S}_{t} &=\\mathbf{R}_{t}+\\mathbf{H}_{t} \\mathbf{P}_{t | t-1} \\mathbf{H}_{t}^{T} \\\\ \\mathbf{K}_{t} &=\\mathbf{P}_{t | t-1} \\mathbf{H}_{t}^{T} \\mathbf{S}_{t}^{-1} \\\\ \\mathbf{z}_{t | t} &=\\mathbf{z}_{t | t-1}+\\mathbf{K}_{t} \\mathbf{r}_{t} \\\\ \\mathbf{P}_{t | t} &=\\left(\\mathbf{I}-\\mathbf{K}_{t} \\mathbf{H}_{t}\\right) \\mathbf{P}_{t | t-1} \\end{aligned}$  \n",
    "\n",
    "f predictor(equation (10), (11) in the paper):  \n",
    "$\\tilde{\\mathbf{y}}_{t}=f_{\\text {predictor }}\\left(\\mathbf{z}_{t | t}\\right)$  \n",
    "$\\hat{\\mathbf{y}}_{t}=f_{\\text {predictor }}\\left(\\mathbf{z}_{t | t-1}\\right)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixyz\n",
    "from pixyz.utils import print_latex\n",
    "from pixyz.distributions import Normal, Deterministic, Dirichlet, Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0\n"
     ]
    }
   ],
   "source": [
    "print(pixyz.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "x_dim = 10\n",
    "a_dim = 10\n",
    "sigma_dim =10\n",
    "z_dim = 10\n",
    "h_dim = 10\n",
    "k_dim = 10\n",
    "y_dim = 10\n",
    "t_max = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_encoder\n",
    "class Encoder(Deterministic):\n",
    "    def __init__(self, x_dim, a_dim, sigma_dim):\n",
    "        super(Encoder, self).__init__(cond_var=[\"x\"], var=[\"a\", \"R\"])\n",
    "        self.fc1 = nn.Linear(x_dim, 100)\n",
    "        self.fc21 = nn.Linear(100, a_dim)\n",
    "        self.fc22 = nn.Linear(100, sigma_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        sigma =F.softplus(self.fc22(h))\n",
    "        R = torch.diag_embed(sigma)\n",
    "        return {\"a\": self.fc21(h), \"R\": R}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$p(a,R|x)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(Encoder(x_dim, a_dim, sigma_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.dirichlet import Dirichlet\n",
    "class ResampledTransition(Deterministic):\n",
    "    def __init__(self, z_dim, h_dim, k_dim):\n",
    "        \"\"\"\n",
    "        what is k_dim?\n",
    "        h_dim = k_dim =  z_dim\n",
    "        \"\"\"\n",
    "        super(ResampledTransition, self).__init__(name=\"Transition\", cond_var=[\"z_prev_prev\", \"h_prev\", \"c_prev\"], var=[\"h\", \"c\", \"A\", \"sigma_Q\"])\n",
    "        self.rnn_1 = nn.LSTMCell(z_dim, h_dim)\n",
    "        self.rnn_2 = nn.LSTMCell(h_dim, h_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, k_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, k_dim)\n",
    "        \n",
    "        self.alpha_diagonal = torch.eye(k_dim).to(device)\n",
    "    \n",
    "    def forward(self, z_prev_prev, h_prev, c_prev):\n",
    "        h_1, c_1 = self.rnn_1(z_prev_prev, (h_prev[0], c_prev[0]))\n",
    "        rnn_2_input = self.dropout(h_1)\n",
    "        h_2, c_2 = self.rnn_2(h_1, (h_prev[1], c_prev[1]))\n",
    "        \n",
    "        alpha = F.relu(self.fc1(h_2))\n",
    "        alpha = Dirichlet(alpha.cpu()).rsample().to(device)\n",
    "        sigma_q = F.relu(self.fc2(alpha))\n",
    "        \n",
    "        # convert alpha, sigma_q to (batch_size, z_dim, z_dim) diagonal matrix\n",
    "        A = alpha.unsqueeze(2).expand(*alpha.size(), alpha.size(1))*self.alpha_diagonal\n",
    "        sigma_Q = sigma_q.unsqueeze(2).expand(*sigma_q.size(), sigma_q.size(1))*self.alpha_diagonal\n",
    "        \n",
    "        h = [h_1, h_2]\n",
    "        c = [c_1, c_2]\n",
    "        \n",
    "        return {\"h\": h, \"c\": c, \"A\": A, \"sigma_Q\": sigma_Q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$Transition(h,c,A,\\sigma_{Q}|z_{prev prev},h_{prev},c_{prev})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(ResampledTransition(z_dim, h_dim, k_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanPredictor(Deterministic):\n",
    "    def __init__(self, z_dim):\n",
    "        super(KalmanPredictor, self).__init__(name=\"KalmanPredictor\", cond_var=[\"z_prev_prev\", \"P_prev_prev\", \"A\", \"sigma_Q\"], var=[\"z_prev\", \"P_prev\"])\n",
    "        \n",
    "        # init Q somehow\n",
    "        self.Q = torch.tensor(0.08 * np.eye(z_dim, dtype=np.float32)).to(device)\n",
    "        self.Q = self.Q.unsqueeze(0)\n",
    "        self.Q = self.Q.repeat(batch_size, 1, 1) # (bs, dim_z, dim_z)\n",
    "    \n",
    "    def forward(self, z_prev_prev, P_prev_prev, A, sigma_Q):\n",
    "        \"\"\"\n",
    "        z_prev_prev: (batch_size, z_dim)\n",
    "        P_prev_prev: (batch_size, z_dim, z_dim)\n",
    "        A: (batch_size, z_dim, z_dim)\n",
    "        \"\"\"\n",
    "        Q = self.Q + sigma_Q\n",
    "    \n",
    "        # z_prev: (batch_size, z_dim)\n",
    "        z_prev = torch.bmm(A, z_prev_prev.unsqueeze(2)).squeeze(2)\n",
    "        # P_prev: (batch_size, z_dim, z_dim)\n",
    "        P_prev = torch.bmm(torch.bmm(A, P_prev_prev), A.transpose(2, 1)) + self.Q\n",
    "        return {\"z_prev\": z_prev, \"P_prev\": P_prev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$KalmanPredictor(z_{prev},P_{prev}|z_{prev prev},P_{prev prev},A,\\sigma_{Q})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(KalmanPredictor(z_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanUpdator(Deterministic):\n",
    "    def __init__(self, a_dim, z_dim):\n",
    "        super(KalmanUpdator, self).__init__(name=\"KalmanUpdator\", cond_var=[\"z_prev\", \"P_prev\", \"a\", \"R\"], var=[\"z\", \"P\"])\n",
    "        # assume a_dim == z_dim\n",
    "        \n",
    "        # for section 3.3 setting\n",
    "        # self.H (batch_size, a_dim, 2 * a_dim)\n",
    "        # self.H =torch.from_numpy(np.array([np.concatenate((np.eye(a_dim).astype(np.float32),\n",
    "        #                                                             np.zeros((a_dim, a_dim)).astype(np.float32)), axis=1)\n",
    "        #                                             for _ in range(batch_size)])\n",
    "        \n",
    "        self.H = torch.eye(a_dim, z_dim).to(device)\n",
    "        self.H = self.H.unsqueeze(0)\n",
    "        self.H = self.H.repeat(batch_size, 1, 1)\n",
    "        \n",
    "        # self.I (batch_size, a_dim, z_dim)\n",
    "        self.I = torch.eye(a_dim, z_dim).to(device)\n",
    "        self.I = self.I.unsqueeze(0)\n",
    "        self.I = self.I.repeat(batch_size, 1, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, z_prev, P_prev, a, R):\n",
    "        \"\"\"\n",
    "        z_prev: (batch_size, z_dim)\n",
    "        P_prev: (batch_size, z_dim, z_dim)\n",
    "        a (observation): (batch_size, a_dim)\n",
    "        H: (a_dim, z_dim)\n",
    "        R: (batch_size, a_dim, a_dim)\n",
    "        \"\"\"\n",
    "        # r (batch_size, a_dim)\n",
    "        r = a - torch.bmm(self.H, z_prev.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        # S: (batch_size, a_dim, a_dim)\n",
    "        S = R + torch.bmm(torch.bmm(self.H, P_prev), self.H.transpose(2, 1))\n",
    "        \n",
    "        # K: (batch_size, a_dim, a_dim)\n",
    "        K = torch.bmm(torch.bmm(P_prev, self.H.transpose(2, 1)), S.inverse())\n",
    "        \n",
    "        # z: (batch_size, z_dim)\n",
    "        z = z_prev + torch.bmm(K, r.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        # P: (batch_size, z_dim, z_dim)\n",
    "        P = torch.bmm((self.I - torch.bmm(K, self.H)), P_prev)\n",
    "        return {\"z\": z, \"P\": P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$KalmanUpdator(z,P|z_{prev},P_{prev},a,R)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(KalmanUpdator(a_dim, z_dim).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPredictor(Bernoulli):\n",
    "    def __init__(self, z_dim, y_dim):\n",
    "        super(FPredictor, self).__init__(name=\"f_predictor\", cond_var=[\"z\"], var=[\"y\"])\n",
    "        \n",
    "        self.fc1 = nn.Linear(z_dim, 100)\n",
    "        self.fc2 = nn.Linear(100, y_dim)\n",
    "        self.scale = torch.ones(y_dim).to(device)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.fc1(z))\n",
    "        #return {\"loc\": self.fc2(h), \"scale\": self.scale}\n",
    "        return {\"probs\": torch.sigmoid(self.fc2(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$f_{predictor}(y|z)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(FPredictor(z_dim, y_dim).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss(in progress)\n",
    "Loss(equation (12) in the paper)  \n",
    "$L(\\theta)=\\frac{1}{T} \\sum_{t=1}^{T}\\left(\\left\\|\\mathbf{y}_{t}-\\tilde{\\mathbf{y}}_{t}\\right\\|^{2}+\\left\\|\\mathbf{y}_{t}-\\hat{\\mathbf{y}}_{t}\\right\\|^{2}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$- sum \\left(\\log f_{predictor}(y|z) \\right) - sum \\left(\\log f_{predictor}(y|z_{prev}) \\right)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pixyz.losses import LogProb, IterativeLoss\n",
    "from pixyz.distributions import ReplaceVarDistribution\n",
    "\n",
    "encoder = Encoder(x_dim, a_dim, sigma_dim).to(device)\n",
    "transition = ResampledTransition(z_dim, h_dim, k_dim).to(device)\n",
    "kalman_predictor = KalmanPredictor(z_dim).to(device)\n",
    "kalman_updator = KalmanUpdator(a_dim, z_dim).to(device)\n",
    "f_predictor = FPredictor(z_dim, y_dim).to(device)\n",
    "\n",
    "# loss\n",
    "loss_tilda = -LogProb(f_predictor).sum()\n",
    "loss_hat = -LogProb(ReplaceVarDistribution(f_predictor, {\"z\": \"z_prev\"})).sum()\n",
    "\n",
    "step_loss = loss_tilda + loss_hat\n",
    "# loss = IterativeLoss(step_loss, max_iter=t_max, \n",
    "#                       series_var=[\"x\"], update_value={\"z\": \"z_prev_prev\", \"P\": \"P_prev_prev\", \"h\": \"h_prev\", \"c\": \"c_prev\"}).mean()\n",
    "print_latex(step_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "x_dim = 28\n",
    "a_dim = 10\n",
    "sigma_dim =10\n",
    "z_dim = 10\n",
    "h_dim = 10\n",
    "k_dim = 10\n",
    "y_dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate MNIST by stacking row images(consider row as time step)\n",
    "def init_dataset(f_batch_size):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    data_dir = '../data'\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda data: data[0])\n",
    "    ])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=True, download=True,\n",
    "                       transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=False, transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, drop_last=True , **kwargs)\n",
    "\n",
    "    fixed_t_size = 28\n",
    "    return train_loader, test_loader, fixed_t_size\n",
    "\n",
    "train_loader, test_loader, t_max = init_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.models import Model\n",
    "\n",
    "class DynaNet(Model):\n",
    "    def __init__(self,\n",
    "                 optimizer=optim.Adam,\n",
    "                 optimizer_params={},\n",
    "                 clip_grad_norm=None,\n",
    "                 clip_grad_value=None):\n",
    "        \n",
    "        # distribution\n",
    "        self.encoder = Encoder(x_dim, a_dim, sigma_dim).to(device)\n",
    "        self.transition = ResampledTransition(z_dim, h_dim, k_dim).to(device)\n",
    "        self.kalman_predictor = KalmanPredictor(z_dim).to(device)\n",
    "        self.kalman_updator = KalmanUpdator(a_dim, z_dim).to(device)\n",
    "        self.f_predictor = FPredictor(z_dim, y_dim).to(device)\n",
    "        \n",
    "        self.sampler = self.encoder * self.transition * self.kalman_predictor * self.kalman_updator\n",
    "        \n",
    "        # loss\n",
    "        loss_tilda = -LogProb(self.f_predictor)\n",
    "        loss_hat = -LogProb(ReplaceVarDistribution(self.f_predictor, {\"z\": \"z_prev\"}))\n",
    "        self.step_loss = loss_tilda.sum() + loss_hat.sum()\n",
    "        \n",
    "        distributions = [self.encoder, self.transition, self.f_predictor]\n",
    "        self.distributions = nn.ModuleList(distributions)\n",
    "\n",
    "        # set params and optim\n",
    "        params = self.distributions.parameters()\n",
    "        self.optimizer = optimizer(params, **optimizer_params)\n",
    "\n",
    "        self.clip_norm = clip_grad_norm\n",
    "        self.clip_value = clip_grad_value\n",
    "        \n",
    "        \n",
    "    \n",
    "    def calculate_loss(self, input_var_dict={}):\n",
    "        batch_size = input_var_dict['x'].size()[1]\n",
    "        x = input_var_dict['x']\n",
    "        \n",
    "        z_prev_prev = torch.zeros([batch_size, z_dim]).to(device)\n",
    "        h_prev = -1. + 2 * torch.rand([2, batch_size, h_dim]).to(device)\n",
    "        c_prev = torch.randn([2, batch_size, h_dim]).to(device)\n",
    "        P_prev_prev = 20 * torch.eye(z_dim).to(device)\n",
    "        P_prev_prev = P_prev_prev.unsqueeze(0)\n",
    "        P_prev_prev = P_prev_prev.repeat(batch_size, 1, 1)\n",
    "        \n",
    "        input_var_dict[\"z_prev_prev\"] = z_prev_prev\n",
    "        input_var_dict[\"h_prev\"] = h_prev\n",
    "        input_var_dict[\"c_prev\"] = c_prev\n",
    "        input_var_dict[\"P_prev_prev\"] = P_prev_prev\n",
    "        # Without Iterative Loss\n",
    "        total_loss = 0\n",
    "        for time_step in range(t_max):\n",
    "            input_var_dict[\"x\"] = x[time_step]\n",
    "            sampled_dict = self.sampler.sample(input_var_dict)\n",
    "            \n",
    "            # following procedure shows what self.sampler.sample() does\n",
    "            \"\"\"\n",
    "            ---------------------------------------------------\n",
    "            encoded = self.encoder.sample({\"x\": x[time_step]})\n",
    "            \n",
    "            a, R = encoded[\"a\"], encoded[\"R\"]\n",
    "            \n",
    "            transition_output = self.transition.sample({\"z_prev_prev\": z_prev_prev, \"h_prev\": h_prev, \"c_prev\": c_prev})\n",
    "            h = transition_output[\"h\"]\n",
    "            c = transition_output[\"c\"]\n",
    "            A = transition_output[\"A\"]\n",
    "            sigma_Q = transition_output[\"sigma_Q\"]\n",
    "            \n",
    "            kalman_predicted = self.kalman_predictor.sample({\"z_prev_prev\": z_prev_prev, \"P_prev_prev\": P_prev_prev, \"A\": A, \"sigma_Q\": sigma_Q})\n",
    "            z_prev = kalman_predicted[\"z_prev\"]\n",
    "            P_prev = kalman_predicted[\"P_prev\"]\n",
    "\n",
    "            kalman_updated = self.kalman_updator.sample({\"z_prev\": z_prev, \"P_prev\": P_prev, \"a\": a, \"R\": R})\n",
    "            z, P = kalman_updated[\"z\"], kalman_updated[\"P\"]\n",
    "            ----------------------------------------------------\n",
    "            \"\"\"\n",
    "            \n",
    "            # update\n",
    "            input_var_dict[\"h_prev\"] = sampled_dict[\"h\"]\n",
    "            input_var_dict[\"c_prev\"] = sampled_dict[\"c\"]\n",
    "            input_var_dict[\"z_prev_prev\"] = sampled_dict[\"z\"]\n",
    "            input_var_dict[\"P_prev_prev\"] = sampled_dict[\"P\"]\n",
    "            \n",
    "            sampled_dict[\"y\"] = x[time_step]\n",
    "            \n",
    "            # loss\n",
    "            total_loss += self.step_loss.eval(sampled_dict)\n",
    "        \n",
    "        total_loss = total_loss / t_max\n",
    "        return total_loss\n",
    "    \n",
    "    def train(self, train_x_dict={}):\n",
    "        self.distributions.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.calculate_loss(train_x_dict)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "\n",
    "        if self.clip_norm:\n",
    "            clip_grad_norm_(self.distributions.parameters(), self.clip_norm)\n",
    "        if self.clip_value:\n",
    "            clip_grad_value_(self.distributions.parameters(), self.clip_value)\n",
    "\n",
    "        # update params\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "    def test(self, test_x_dict={}):\n",
    "        self.distributions.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = self.calculate_loss(test_x_dict)\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def reconst_image(self, original_data):\n",
    "        self.distributions.eval()\n",
    "        with torch.no_grad():\n",
    "            xs = []\n",
    "            x = original_data.transpose(0, 1)\n",
    "            batch_size = original_data.size()[0]\n",
    "            z_prev_prev = torch.zeros([batch_size, z_dim]).to(device)\n",
    "            h_prev = -1. + 2 * torch.rand([2, batch_size, h_dim]).to(device)\n",
    "            c_prev = torch.randn([2, batch_size, h_dim]).to(device)\n",
    "            P_prev_prev = 20 * torch.eye(z_dim).to(device)\n",
    "            P_prev_prev = P_prev_prev.unsqueeze(0)\n",
    "            P_prev_prev = P_prev_prev.repeat(batch_size, 1, 1)\n",
    "            \n",
    "            input_var_dict = {\"z_prev_prev\": z_prev_prev, \"h_prev\": h_prev, \"c_prev\": c_prev, \"P_prev_prev\": P_prev_prev}\n",
    "            for time_step in range(t_max):\n",
    "                input_var_dict[\"x\"] = x[time_step]\n",
    "                sampled_dict = self.sampler.sample(input_var_dict)\n",
    "\n",
    "                # update\n",
    "                input_var_dict[\"h_prev\"] = sampled_dict[\"h\"]\n",
    "                input_var_dict[\"c_prev\"] = sampled_dict[\"c\"]\n",
    "                input_var_dict[\"z_prev_prev\"] = sampled_dict[\"z\"]\n",
    "                input_var_dict[\"P_prev_prev\"] = sampled_dict[\"P\"]\n",
    "                dec_x = self.f_predictor.sample_mean({\"z\": sampled_dict[\"z\"]})\n",
    "                xs.append(dec_x[None, :])\n",
    "            recon_img = torch.cat(xs, dim=0).transpose(0, 1)\n",
    "        return recon_img\n",
    "    \n",
    "    def generate_nstep(self, original_data, n_step=14):\n",
    "        self.distributions.eval()\n",
    "        with torch.no_grad():\n",
    "            xs = []\n",
    "            x = original_data.transpose(0, 1)\n",
    "            batch_size = original_data.size()[0]\n",
    "            z_prev_prev = torch.zeros([batch_size, z_dim]).to(device)\n",
    "            h_prev = -1. + 2 * torch.rand([2, batch_size, h_dim]).to(device)\n",
    "            c_prev = torch.randn([2, batch_size, h_dim]).to(device)\n",
    "            P_prev_prev = 20 * torch.eye(z_dim).to(device)\n",
    "            P_prev_prev = P_prev_prev.unsqueeze(0)\n",
    "            P_prev_prev = P_prev_prev.repeat(batch_size, 1, 1)\n",
    "            \n",
    "            input_var_dict = {\"z_prev_prev\": z_prev_prev, \"h_prev\": h_prev, \"c_prev\": c_prev, \"P_prev_prev\": P_prev_prev}\n",
    "            for time_step in range(t_max):\n",
    "                if time_step < n_step:\n",
    "                    input_var_dict[\"x\"] = x[time_step]\n",
    "                    sampled_dict = self.sampler.sample(input_var_dict)\n",
    "\n",
    "                    # update\n",
    "                    input_var_dict[\"h_prev\"] = sampled_dict[\"h\"]\n",
    "                    input_var_dict[\"c_prev\"] = sampled_dict[\"c\"]\n",
    "                    input_var_dict[\"z_prev_prev\"] = sampled_dict[\"z\"]\n",
    "                    input_var_dict[\"P_prev_prev\"] = sampled_dict[\"P\"]\n",
    "                    dec_x = self.f_predictor.sample_mean({\"z\": sampled_dict[\"z\"]})\n",
    "                else:\n",
    "                    transition_output = self.transition.sample({\"z_prev_prev\": z_prev_prev, \"h_prev\": h_prev, \"c_prev\": c_prev})\n",
    "                    h = transition_output[\"h\"]\n",
    "                    c = transition_output[\"c\"]\n",
    "                    A = transition_output[\"A\"]\n",
    "                    sigma_Q = transition_output[\"sigma_Q\"]\n",
    "\n",
    "\n",
    "                    kalman_predicted = self.kalman_predictor.sample({\"z_prev_prev\": z_prev_prev, \"P_prev_prev\": P_prev_prev, \"A\": A, \"sigma_Q\": sigma_Q})\n",
    "                    z_prev = kalman_predicted[\"z_prev\"]\n",
    "                    P_prev = kalman_predicted[\"P_prev\"]\n",
    "                    # update\n",
    "                    h_prev = h\n",
    "                    c_prev = c\n",
    "                    z_prev_prev = z_prev\n",
    "                    P_prev_prev = P_prev\n",
    "                    dec_x = self.f_predictor.sample_mean({\"z\": z_prev})\n",
    "                    \n",
    "                xs.append(dec_x[None, :])\n",
    "            generated_img = torch.cat(xs, dim=0).transpose(0, 1)\n",
    "        return generated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9857.7939, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x, _ = iter(test_loader).next()\n",
    "fixed_batch = _x.to(device)\n",
    "batch_size = fixed_batch.size()[0]\n",
    "sequential_x = fixed_batch.transpose(0, 1)\n",
    "\n",
    "dynanet = DynaNet()\n",
    "dynanet.calculate_loss(input_var_dict={'x': sequential_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loop(epoch, loader, model, device, train_mode=False):\n",
    "    mean_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        data = data.to(device)\n",
    "        batch_size = data.size()[0]\n",
    "        x = data.transpose(0, 1)\n",
    "        #q_z_prev = torch.zeros(batch_size, z_dim).to(device)\n",
    "        if train_mode:\n",
    "            mean_loss += model.train({'x': x}) * batch_size\n",
    "        else:\n",
    "            mean_loss += model.test({'x': x}) * batch_size\n",
    "    mean_loss /= len(loader.dataset)\n",
    "    if train_mode:\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(epoch, mean_loss))\n",
    "    else:\n",
    "        print('Test loss: {:.4f}'.format(mean_loss))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "dt_now = datetime.datetime.now()\n",
    "exp_time = dt_now.strftime('%Y%m%d_%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [01:06<00:00,  3.54it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 4728.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:04<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2780.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [01:07<00:00,  3.47it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train loss: 2540.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:05<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2402.5258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [01:07<00:00,  3.46it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train loss: 2367.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:05<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2320.4956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [01:07<00:00,  3.46it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train loss: 2305.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:05<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2266.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [01:07<00:00,  3.45it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train loss: 2258.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:05<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2224.5651\n"
     ]
    }
   ],
   "source": [
    "import pixyz\n",
    "v = pixyz.__version__\n",
    "writer = SummaryWriter(\"../runs/\" + v + \".dynanet\" + exp_time)\n",
    "# fixed _x for watching reconstruction improvement\n",
    "_x, _ = iter(test_loader).next()\n",
    "_x = _x.to(device)\n",
    "dynanet = DynaNet(optimizer=optim.Adam, optimizer_params={'lr': 1e-3})\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = data_loop(epoch, train_loader, dynanet, device, train_mode=True)\n",
    "    test_loss = data_loop(epoch, test_loader, dynanet, device)\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss', test_loss, epoch)\n",
    "    \n",
    "    recon_img = dynanet.reconst_image(_x)\n",
    "    writer.add_images('Reconstructed',  recon_img[:, None], epoch)\n",
    "    \n",
    "    generated_img = dynanet.generate_nstep(_x)\n",
    "    writer.add_images('Generated',  generated_img[:, None], epoch)\n",
    "    \n",
    "    writer.add_images('orignal', _x[:, None], epoch)\n",
    "elapsed_time = time.time() - start\n",
    "writer.add_scalar('Exp time second', elapsed_time)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
